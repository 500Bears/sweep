{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "engine = None\n",
      "            if model in OPENAI_EXCLUSIVE_MODELS and OPENAI_API_TYPE != \"azure\":\n",
      "                logger.info(f\"Calling OpenAI exclusive model. {model}\")\n",
      "                raise Exception(\"OpenAI exclusive model.\")\n",
      "            if (\n",
      "                model == \"gpt-3.5-turbo-16k\"\n",
      "                or model == \"gpt-3.5-turbo-16k-0613\"\n",
      "                and OPENAI_API_ENGINE_GPT35 is not None\n",
      "            ):\n",
      "                engine = OPENAI_API_ENGINE_GPT35\n",
      "            elif (\n",
      "                model == \"gpt-4\"\n",
      "                or model == \"gpt-4-0613\"\n",
      "                and OPENAI_API_ENGINE_GPT4 is not None\n",
      "            ):\n",
      "                engine = OPENAI_API_ENGINE_GPT4\n",
      "            elif (\n",
      "                model == \"gpt-4-32k\"\n",
      "                or model == \"gpt-4-32k-0613\"\n",
      "                and OPENAI_API_ENGINE_GPT4_32K is not None\n",
      "            ):\n",
      "                engine = OPENAI_API_ENGINE_GPT4_32K\n",
      "767 1664\n",
      "--- a/tests/notebooks/src/test.py\n",
      "+++ b/tests/notebooks/src/test.py\n",
      "@@ -37,28 +37,7 @@\n",
      "     @file_cache(ignore_params=[])\n",
      "     def call_openai(self, model, messages, max_tokens, temperature) -> str:\n",
      "         try:\n",
      "-            engine = None\n",
      "-            if model in OPENAI_EXCLUSIVE_MODELS and OPENAI_API_TYPE != \"azure\":\n",
      "-                logger.info(f\"Calling OpenAI exclusive model. {model}\")\n",
      "-                raise Exception(\"OpenAI exclusive model.\")\n",
      "-            if (\n",
      "-                model == \"gpt-3.5-turbo-16k\"\n",
      "-                or model == \"gpt-3.5-turbo-16k-0613\"\n",
      "-                and OPENAI_API_ENGINE_GPT35 is not None\n",
      "-            ):\n",
      "-                engine = OPENAI_API_ENGINE_GPT35\n",
      "-            elif (\n",
      "-                model == \"gpt-4\"\n",
      "-                or model == \"gpt-4-0613\"\n",
      "-                and OPENAI_API_ENGINE_GPT4 is not None\n",
      "-            ):\n",
      "-                engine = OPENAI_API_ENGINE_GPT4\n",
      "-            elif (\n",
      "-                model == \"gpt-4-32k\"\n",
      "-                or model == \"gpt-4-32k-0613\"\n",
      "-                and OPENAI_API_ENGINE_GPT4_32K is not None\n",
      "-            ):\n",
      "-                engine = OPENAI_API_ENGINE_GPT4_32K\n",
      "+            engine = self.helper(model)\n",
      "             if OPENAI_API_TYPE is None or engine is None:\n",
      "                 openai.api_key = OPENAI_API_KEY\n",
      "                 openai.api_base = \"https://api.openai.com/v1\"\n",
      "@@ -152,3 +131,28 @@\n",
      "             logger.error(f\"OpenAI API Key not found and Azure Error: {e}\")\n",
      "             # Raise exception to report error\n",
      "             raise e\n",
      "+\n",
      "+    def helper(self, model):\n",
      "+        engine = None\n",
      "+        if model in OPENAI_EXCLUSIVE_MODELS and OPENAI_API_TYPE != \"azure\":\n",
      "+            logger.info(f\"Calling OpenAI exclusive model. {model}\")\n",
      "+            raise Exception(\"OpenAI exclusive model.\")\n",
      "+        if (\n",
      "+            model == \"gpt-3.5-turbo-16k\"\n",
      "+            or model == \"gpt-3.5-turbo-16k-0613\"\n",
      "+            and OPENAI_API_ENGINE_GPT35 is not None\n",
      "+        ):\n",
      "+            engine = OPENAI_API_ENGINE_GPT35\n",
      "+        elif (\n",
      "+            model == \"gpt-4\"\n",
      "+            or model == \"gpt-4-0613\"\n",
      "+            and OPENAI_API_ENGINE_GPT4 is not None\n",
      "+        ):\n",
      "+            engine = OPENAI_API_ENGINE_GPT4\n",
      "+        elif (\n",
      "+            model == \"gpt-4-32k\"\n",
      "+            or model == \"gpt-4-32k-0613\"\n",
      "+            and OPENAI_API_ENGINE_GPT4_32K is not None\n",
      "+        ):\n",
      "+            engine = OPENAI_API_ENGINE_GPT4_32K\n",
      "+        return engine\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import rope.base.project\n",
    "from rope.refactor.extract import ExtractMethod\n",
    "import re\n",
    "\n",
    "APOSTROPHE_MARKER = \"__APOSTROPHE__\"\n",
    "PERCENT_FORMAT_MARKER = \"__PERCENT_FORMAT__\"\n",
    "\n",
    "def serialize(text: str):\n",
    "    # Replace \"'{var}'\" with \"__APOSTROPHE__{var}__APOSTROPHE__\"\n",
    "    text = re.sub(r\"'{([^'}]*?)}'\", f\"{APOSTROPHE_MARKER}{{\\\\1}}{APOSTROPHE_MARKER}\", text)\n",
    "    # Replace \"%s\" with \"__PERCENT_FORMAT__\"\n",
    "    text = re.sub(r\"%\\((.*?)\\)s\", f\"{PERCENT_FORMAT_MARKER}{{\\\\1}}\", text)\n",
    "    return text\n",
    "\n",
    "def deserialize(text: str):\n",
    "    text = re.sub(f\"{APOSTROPHE_MARKER}{{(.*?)}}{APOSTROPHE_MARKER}\", \"'{\\\\1}'\", text)\n",
    "    text = re.sub(f\"{PERCENT_FORMAT_MARKER}{{(.*?)}}\", \"%(\\\\1)s\", text)\n",
    "    return text\n",
    "\n",
    "myproject = rope.base.project.Project('../../')\n",
    "\n",
    "myresource = myproject.get_resource('tests/notebooks/src/test.py')\n",
    "contents = myresource.read()\n",
    "serialized_contents = serialize(myresource.read())\n",
    "myresource.write(serialized_contents)\n",
    "extract_span = r\"\"\"if (\n",
    "                MULTI_REGION_CONFIG is None\n",
    "                or not isinstance(MULTI_REGION_CONFIG, list)\n",
    "                or len(MULTI_REGION_CONFIG) == 0\n",
    "                or not isinstance(MULTI_REGION_CONFIG[0], list)\n",
    "            ):\n",
    "                logger.info(\n",
    "                    f\"Calling {model} with engine {engine} on Azure url {OPENAI_API_BASE}.\"\n",
    "                )\n",
    "                openai.api_type = OPENAI_API_TYPE\n",
    "                openai.api_base = OPENAI_API_BASE\n",
    "                openai.api_version = OPENAI_API_VERSION\n",
    "                openai.api_key = AZURE_API_KEY\"\"\"\n",
    "serialized_extract_span = serialize(extract_span)\n",
    "print(serialized_extract_span)\n",
    "\n",
    "start, end = serialized_contents.find(serialized_extract_span), serialized_contents.find(serialized_extract_span) + len(serialized_extract_span)\n",
    "print(start, end)\n",
    "\n",
    "try:\n",
    "    extractor = ExtractMethod(myproject, myresource, start, end)\n",
    "    change_set = extractor.get_changes(\"helper\", similar=True)\n",
    "    for change in change_set.changes:\n",
    "        if change.old_contents is not None:\n",
    "            change.old_contents = deserialize(change.old_contents)\n",
    "        else:\n",
    "            change.old_contents = deserialize(change.resource.read())\n",
    "        change.new_contents = deserialize(change.new_contents)\n",
    "    for change in change_set.changes:\n",
    "        print(change.get_description())\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    myresource.write(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(change.new_contents) - len(change.old_contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 ('sweepai-u_CIt3kb-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "25d341f3248a096a89b9dbf6eec8e41f63aed02f6ba059df22a49224e3e8f1b0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
